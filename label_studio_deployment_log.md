# Отчет по развертыванию, использованию и проверке Label Studio

## 1. Развертывание Label Studio

### 1.1. Предварительные требования
*   Установленный Docker Desktop (для Windows).
*   Доступ в Интернет для скачивания образа Label Studio.
*   Python 3.x с установленной библиотекой `opencv-python` для скрипта визуализации.

### 1.2. Выбор способа развертывания
Для локального развертывания с сохранением данных был выбран метод запуска Docker-контейнера с помощью команды `docker run` с монтированием тома (bind mount) для хранения данных Label Studio. Этот способ обеспечивает персистентность данных между запусками контейнера и прямой доступ к файлам на хост-машине.

### 1.3. Шаги развертывания

1.  **Создание локальной директории для данных Label Studio:**
    Была создана директория на локальной машине для хранения всех данных Label Studio (проекты, конфигурации, загруженные файлы).
    *   **Путь на хост-машине (Windows, PowerShell):** `C:\Users\maxku\Desktop\comparing-data-markup\label_studio_data`
    *   **Команда (пример для PowerShell):** `mkdir C:\Users\maxku\Desktop\comparing-data-markup\label_studio_data` (или создана через Проводник).

2.  **Запуск контейнера Label Studio:**
    Использовалась следующая команда в PowerShell:
    ```powershell
    docker run -d -p 8080:8080 -v C:\Users\maxku\Desktop\comparing-data-markup\label_studio_data:/label-studio/data --name label-studio-container heartexlabs/label-studio
    ```
    **Разбор команды:**
    *   `docker run`: запуск нового контейнера.
    *   `-d`: запуск в фоновом (detached) режиме.
    *   `-p 8080:8080`: проброс порта 8080 хоста на порт 8080 контейнера.
    *   `-v C:\Users\maxku\Desktop\comparing-data-markup\label_studio_data:/label-studio/data`: монтирование тома.
        *   `C:\Users\maxku\Desktop\comparing-data-markup\label_studio_data`: путь к созданной директории на хост-машине.
        *   `:/label-studio/data`: путь внутри контейнера, где Label Studio хранит свои данные.
    *   `--name label-studio-container`: присвоение имени контейнеру для удобства управления.
    *   `heartexlabs/label-studio`: имя официального Docker-образа Label Studio.

3.  **Проверка статуса контейнера:**
    Командой `docker ps` был проверен успешный запуск контейнера. Контейнер `label-studio-container` отображался со статусом `Up`.

4.  **Доступ к Label Studio и создание аккаунта:**
    Label Studio стал доступен в браузере по адресу `http://localhost:8080`. При первом входе был создан аккаунт администратора.

### 1.4. Структура хранения данных на хосте
После запуска и импорта данных, в директории `C:\Users\maxku\Desktop\comparing-data-markup\label_studio_data` была обнаружена следующая структура (фрагмент):
```
label_studio_data/
├── media/
│   └── upload/
│       └── 1/  # PROJECT_ID
│           ├── 0ea11ae6-pexels-thatguyc...jpg
│           └── ... (другие изображения)
├── export/
│   └── project-1-at-....json # Экспортированные аннотации
└── label_studio.sqlite3      # База данных Label Studio
```

### 1.5. Сложности и решения при развертывании и настройке

*   **Проблема с отображением изображений в интерфейсе разметки (начальная):**
    *   **Симптом:** Ошибка "There was an issue loading URL from $undefined$ value" при попытке открыть изображение для разметки.
    *   **Причина:** Некорректное значение переменной в XML-конфигурации интерфейса разметки для тега `<Image>`. По умолчанию стояло `$undefined$`.
    *   **Решение:** В настройках интерфейса разметки (Settings -> Labeling Interface -> Code) для тега `<Image>` был установлен атрибут `value="$image"`.

## 2. Тестовая разметка

### 2.1. Создание проекта
*   В Label Studio был создан новый проект с именем `Cat Detection Test`.
*   Цель проекта: разметка изображений для задачи детекции объектов.

### 2.2. Подготовка и импорт датасета
*   **Данные:** Было подготовлено 14 изображений кошек.
*   **Источник:** Изображения были скачаны с ресурса Pexels.com.
*   **Формат:** `.jpg`.
*   **Импорт:** Изображения были загружены в проект через стандартную функцию "Import" в Label Studio (File Upload).

### 2.3. Настройка интерфейса разметки
Для задачи детекции объектов (bounding boxes) использовалась следующая XML-конфигурация интерфейса (Settings -> Labeling Interface -> Code):
```xml
<View>
  <Image name="image" value="$image"/>
  <RectangleLabels name="label" toName="image">
    <Label value="Cat" background="blue"/>
    <Label value="Cats" background="green"/> 
  </RectangleLabels>
</View>
```

### 2.4. Выполнение разметки
*   Все 14 импортированных изображений были размечены с использованием инструмента "Bounding Box".
*   Для каждой обнаруженной кошки на изображении рисовался прямоугольник и присваивалась метка "Cat" и для каждой группы кошек метка "Cats".

## 3. Экспорт и проверка разметки

### 3.1. Экспорт данных
*   После завершения разметки всех задач, аннотации были экспортированы из Label Studio.
*   **Формат экспорта:** JSON (стандартный формат, содержащий полную информацию о задачах и аннотациях).
*   Пример структуры экспортированного JSON для одной задачи (фрагмент):
    ```json
    [
      {
        "id": 1,
        "annotations": [
          {
            "id": 1,
            "completed_by": 1,
            "result": [
              {
                "original_width": 3606,
                "original_height": 5409,
                "image_rotation": 0,
                "value": {
                  "x": 29.471544715447155,
                  "y": 17.615176151761517,
                  "width": 47.76422764227644,
                  "height": 69.64769647696477,
                  "rotation": 0,
                  "rectanglelabels": ["Cat"]
                },
                "id": "awOF7HsKlJ",
                "from_name": "label",
                "to_name": "image",
                "type": "rectanglelabels",
                "origin": "manual"
              }
            ],
            // ... другие поля аннотации ...
          }
        ],
        "file_upload": "48c220e9-pexels-fox-58267-762986.jpg",
        "data": {
          "image": "/data/upload/1/48c220e9-pexels-fox-58267-762986.jpg" // Ключевой путь!
        },
        // ... другие поля задачи ...
      }
      // ... другие задачи ...
    ]
    ```

### 3.2. Проверка разметки с помощью Python-скрипта
Для визуальной проверки корректности экспортированных аннотаций был разработан и использован Python-скрипт с библиотекой OpenCV.

**Ключевые особенности и сложности при разработке скрипта:**

1.  **Формирование пути к изображениям на хосте:**
    *   **Проблема:** Путь к изображению в JSON (`data.image`) имел вид `/data/upload/PROJECT_ID/filename.jpg`. Физически же файлы на хосте находились в `BASE_HOST_PATH/media/upload/PROJECT_ID/filename.jpg`.
    *   **Решение:** В скрипте была реализована логика преобразования пути из JSON в корректный локальный путь: отсечение префикса `/data/` и добавление `media/` к базовому пути `label_studio_data` на хосте. Также учтены особенности разделителей пути для Windows (`os.sep`).

2.  **Отображение больших изображений:**
    *   **Проблема:** Исходные изображения имели высокое разрешение, что приводило к отображению лишь малой части картинки в окне OpenCV.
    *   **Решение:** Реализовано масштабирование изображения до максимальных размеров (например, 1280x720) с сохранением пропорций перед отображением. Рамки аннотаций рассчитывались на основе оригинальных размеров, а затем рисовались на копии изображения, которая после этого масштабировалась.

3.  **Ошибка OpenCV `NULL window`:**
    *   **Проблема:** При последовательном отображении изображений возникала ошибка `cv2.error: (-27:Null pointer) NULL window ... cvDestroyWindow`.
    *   **Решение:** Каждому отображаемому окну присваивалось уникальное имя (включающее ID задачи). Закрытие окна (`cv2.destroyWindow()`) производилось для конкретного имени окна после `cv2.waitKey(0)`. Добавлен `try-except` для обработки случая, если окно уже было закрыто пользователем.

**Фрагмент Python-скрипта (логика работы с путями и отображением):**
```python
# ... (импорты и определение базовых путей как в предыдущих примерах) ...

# Максимальные размеры для отображаемого окна
MAX_DISPLAY_WIDTH = 1280
MAX_DISPLAY_HEIGHT = 720
WINDOW_NAME_PREFIX = "Label Studio Annotation Viewer"

# ... (цикл по задачам из JSON) ...
    # --- Ключевая часть: формирование правильного пути на хосте ---
    full_image_path_on_host = None
    if image_path_from_json.startswith('/data/upload/'):
        path_suffix = image_path_from_json[len('/data/'):].lstrip('/') 
        path_suffix = path_suffix.replace('/', os.sep) # Для Windows
        full_image_path_on_host = os.path.join(base_data_path_on_host, "media", path_suffix)
    # ... (проверка существования файла) ...

    original_image = cv2.imread(full_image_path_on_host)
    display_image = original_image.copy()
    img_height, img_width = original_image.shape[:2]

    # ... (цикл по аннотациям и результатам, расчет координат x1,y1,x2,y2) ...
        # Рисуем на display_image
        cv2.rectangle(display_image, (x1, y1), (x2, y2), color, line_thickness)
        cv2.putText(display_image, label_text, (text_x, text_y), 
                    cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, line_thickness)
    # ... (конец циклов по аннотациям) ...

    # Масштабирование display_image для отображения
    h_orig, w_orig = display_image.shape[:2]
    scale = min(MAX_DISPLAY_WIDTH / w_orig, MAX_DISPLAY_HEIGHT / h_orig)
    if scale < 1:
        new_w, new_h = int(w_orig * scale), int(h_orig * scale)
        resized_display_image = cv2.resize(display_image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    else:
        resized_display_image = display_image

    current_window_name = f"{WINDOW_NAME_PREFIX} - Task: {task_id_str}"
    cv2.imshow(current_window_name, resized_display_image)
    key = cv2.waitKey(0) 
    
    try:
        cv2.destroyWindow(current_window_name)
    except cv2.error as e:
        print(f"  Info: Не удалось закрыть окно '{current_window_name}' (возможно, закрыто пользователем): {e}")

    if key == 27: break # ESC для выхода
# ... (cv2.destroyAllWindows() в конце) ...
```

**Результат проверки:** Визуализация с помощью скрипта подтвердила, что аннотации были сделаны в целом корректно. Рамки соответствовали объектам на изображениях.

## 4. Впечатления от первого опыта использования Label Studio

*   **Удобство интерфейса:**
    *   **Положительно:** Основной интерфейс для создания проектов, импорта данных и разметки достаточно интуитивен. Процесс рисования bounding box'ов простой и удобный. Возможность настройки горячих клавиш (хотя в данном тесте активно не использовалась) является плюсом.

*   **Понятность настроек:**
    *   **Положительно:** Выбор шаблонов для интерфейса разметки значительно упрощает старт. Базовые настройки проекта понятны.
    *   **Сложности:** Глубокая кастомизация интерфейса через XML требует изучения документации по тегам Label Studio. Формат экспортируемых данных (особенно пути к файлам) требует внимания при последующей программной обработке.

*   **Возникшие вопросы или трудности при самой разметке и работе:**
    *   **Пути к файлам:** Понимание того, как Label Studio хранит файлы и какие пути записывает в экспорт, стало ключевым моментом для внешней обработки данных. Различие между путями в JSON (`/data/upload/...`) и реальной структурой на хосте с подпапкой `media/` потребовало отладки скрипта.
    *   **Масштабирование изображений:** При ручной проверке в Label Studio или при внешней визуализации больших изображений необходимо учитывать масштабирование, чтобы корректно оценить разметку.
    *   **Выбор метки:** Для задачи с небольшим количеством классов это не проблема, но при большом количестве меток может потребоваться более эффективный способ их выбора.

*   **Общее впечатление:** Label Studio является мощным и гибким инструментом для разметки данных. Локальное развертывание через Docker с монтированием тома работает надежно. Основные задачи разметки выполняются легко. Для эффективной интеграции в пайплайны обработки данных важно разобраться со структурой экспорта и путями к файлам. Возможность проверки разметки с помощью внешних скриптов является важным этапом контроля качества.

## 5. Заключение
Задача по развертыванию Label Studio, выполнению тестовой разметки, экспорту и проверке данных успешно выполнена. Получен ценный практический опыт работы с инструментом, выявлены потенциальные сложности и способы их решения. Процесс задокументирован в данном отчете.