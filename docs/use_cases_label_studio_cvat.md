# Use Cases: Полный цикл разметки и обучения с Label Studio и CVAT

## Введение

Целью данного документа является демонстрация полных циклов работы с данными – от их сбора до обучения моделей машинного обучения – с использованием инструментов разметки Label Studio и CVAT. Эти сценарии (Use Cases) призваны наглядно показать практическое применение каждого инструмента в контексте MLOps-пайплайна и помочь в понимании всего процесса.

**Use Case 1: Извлечение именованных сущностей (NER) с помощью Label Studio**

### 1. Сбор и подготовка данных

*   **Описание типа данных:**
    Для данного Use Case мы будем использовать короткие текстовые фрагменты, представляющие собой новостные заголовки и краткие аннотации к новостям. Примерная длина каждого текстового фрагмента – от 1 до 3 предложений. Такой формат удобен для демонстрации процесса разметки NER, так как задачи (тексты) достаточно компактны.

*   **Источники:**
    Данные могут быть получены из различных источников:
    *   Публичные RSS-ленты новостных агентств (например, РИА Новости, Интерфакс).
    *   Парсинг заголовков с новостных веб-сайтов.
    *   Внутренние архивы новостных дайджестов компании.
    Гипотетически, мы могли бы использовать API новостного агрегатора или подготовить выгрузку из базы данных. Для нашего примера, предположим, что данные собраны в простой текстовый файл или CSV, где каждая строка – отдельная новость.

*   **Начальная подготовка:**
    Перед загрузкой в Label Studio может потребоваться минимальная подготовка:
    1.  **Очистка от HTML-тегов:** Если данные получены путем парсинга веб-страниц, необходимо удалить все HTML-теги, оставив только чистый текст.
    2.  **Удаление избыточных пробелов и спецсимволов:** Нормализация пробелов (удаление двойных пробелов, пробелов в начале/конце строки) и удаление нерелевантных спецсимволов (если они не являются частью сущностей).
    3.  **Разбиение на документы/задачи:** Убедиться, что каждый текстовый фрагмент, который будет представлять собой одну задачу для разметки, четко отделен (например, находится на новой строке в файле). Для длинных статей может потребоваться разбивка на абзацы или смысловые блоки. В нашем случае, так как мы работаем с короткими новостями, каждая новость уже является отдельной задачей.

*   **[Текст](data/news_data.txt)**


### 2. Настройка проекта в Label Studio

На этом этапе мы создадим проект в Label Studio, настроим интерфейс для разметки NER и импортируем наши подготовленные текстовые данные.

*   **Создание нового проекта:**
    1.  Войдите в Label Studio.
    2.  Нажмите кнопку "Create Project" (Создать проект).
        ![alt text](image/2.png)
    3.  Введите имя проекта, например, "NER News Analysis". Можно также добавить описание.
    4.  Нажмите "Save" (Сохранить) или "Create" (Создать).

*   **Конфигурация разметки (Labeling Config) для NER:**
    1.  После создания проекта перейдите на вкладку "Settings" (Настройки), а затем в подраздел "Labeling Interface" (Интерфейс разметки).
        ![alt text](image/3.png)
    2.  Здесь необходимо определить XML-конфигурацию для задачи NER. Можно выбрать один из готовых шаблонов ("Named Entity Recognition") и адаптировать его, или написать конфигурацию с нуля.
    3.  Для наших сущностей (`PERSON`, `ORG`, `LOC`, `PRODUCT`) конфигурация может выглядеть так:

        ```xml
        <View>
          <Labels name="label" toName="text">
            <Label value="PERSON" background="#FFD700"/> <!-- Золотой -->
            <Label value="ORG" background="#87CEFA"/>    <!-- Светло-голубой -->
            <Label value="LOC" background="#90EE90"/>    <!-- Светло-зеленый -->
            <Label value="PRODUCT" background="#FFA07A"/> <!-- Светло-лососевый -->
          </Labels>
        
          <Text name="text" value="$text"/> 
        </View>
        ```

        *   **Пояснение:**
            *   `<View>`: Корневой тег.
            *   `<Labels>`: Определяет набор меток (сущностей). `toName="text"` указывает, что эти метки применяются к элементу с `name="text"`.
            *   `<Label>`: Определяет каждую конкретную метку с ее значением (`value`) и цветом фона (`background`) для визуального выделения.
            *   `<Text>`: Определяет, как будут отображаться текстовые данные. `name="text"` — это идентификатор этого блока данных. `value="$text"` указывает, что данные для этого блока будут браться из поля `text` входных данных. **Если вы импортируете простой `.txt` файл (где каждая строка - задача), то можно использовать `value="$text"`. Если вы импортируете CSV файл, где текстовые данные находятся в столбце с именем, например, "text_data", то нужно будет написать `value="$text_data"`**.

    4.  Вставьте этот XML-код в поле "Labeling Config".
        ![alt text](image/4.png)
    5.  Нажмите "Save" (Сохранить).

*   **Импорт данных:**
    1.  Перейдите на главную страницу проекта (обычно кликнув на его имя) или найдите кнопку "Import" (Импорт) или "Add Data" (Добавить данные).
        ![alt text](image/5.png)
    2.  Выберите способ импорта. Для наших текстовых данных, если они сохранены в файле `news_data.txt` (каждая новость на новой строке) или `news_data.csv` (с одним столбцом `text`), выберите "Upload Files" (Загрузить файлы).
    3.  Загрузите ваш файл (`news_data.txt` или `news_data.csv`).
    4.  После загрузки Label Studio обработает файл и отобразит количество импортированных задач.
        ![alt text](image/6.png)


### 3. Процесс разметки

После импорта данных можно приступать непосредственно к разметке.

*   **Описание интерфейса разметки для NER:**
    1.  На странице проекта нажмите кнопку "Label All Tasks" (Начать разметку) или выберите первую неразмеченную задачу из списка.
    2.  Откроется интерфейс разметки. В основной части экрана будет отображаться текст текущей задачи (нашей новости). Сбоку (обычно справа или внизу, в зависимости от конфигурации) будет панель с метками (Labels), которые мы определили в XML (`PERSON`, `ORG`, `LOC`, `PRODUCT`), каждая со своим цветом.

*   **Ключевые действия разметчика:**
    1.  **Чтение текста:** Внимательно прочитать текст задачи.
    2.  **Выделение сущности:** С помощью мыши выделить фрагмент текста, который соответствует одной из определенных сущностей. Например, в тексте "SpaceX, основанная Илоном Маском..." выделить "SpaceX".
    3.  **Выбор метки:** После выделения текста кликнуть на соответствующую метку на панели меток. Например, для "SpaceX" кликнуть на метку `ORG`. Выделенный текст окрасится в цвет, присвоенный этой метке (светло-голубой).
    4.  **Продолжение разметки:** Повторить шаги 2-3 для всех сущностей в текущем тексте. Например, выделить "Илоном Маском" и присвоить метку `PERSON`, "Falcon 9" и "Starlink" – `PRODUCT`, "Ванденберг" и "Калифорнии" – `LOC`.
    5.  **Завершение задачи:** После разметки всех сущностей в текущей задаче нажать кнопку "Submit" (Отправить) или "Update" (Обновить), чтобы сохранить аннотации и перейти к следующей задаче. Если задача по какой-то причине не может быть размечена.
    ![alt text](image/7.png)

### 4. Экспорт размеченных данных

После того как все (или необходимая часть) данных размечены, аннотации нужно экспортировать для дальнейшего использования в обучении модели.

*   **Выбор формата экспорта:**
    1.  На главной странице проекта Label Studio найти и нажать кнопку "Export" (Экспорт).
        ![alt text](image/8.png)
    2.  Откроется окно или страница выбора формата экспорта. Label Studio предлагает несколько форматов. Для задач NER наиболее релевантными и часто используемыми являются:
        *   **JSON:** Это нативный формат Label Studio, который содержит всю информацию об аннотациях, включая смещения символов (start, end) для каждой сущности, что очень удобно для большинства NLP-фреймворков. Существует несколько вариантов JSON (полный, минимальный).
        *   **CONLL2003:** Стандартный формат для задач NER, где каждое слово (токен) и его метка находятся на отдельной строке. Этот формат часто используется в академических исследованиях и некоторыми библиотеками.
        *   **CSV/TSV:** Может быть полезен, если требуется простой табличный вид, но для NER он менее информативен, чем JSON или CONLL.
    3.  Для нашего Use Case, **JSON** является предпочтительным выбором, так как он легко парсится и содержит точную информацию о позициях сущностей. Выберем его.
    4.  Нажмите кнопку "Export" (Экспорт) для выбранного формата. Файл с аннотациями будет загружен на ваш компьютер ([Например](data/project-14-at-2025-06-25-13-18-72190ffe.json)).

*   **Описание структуры экспортируемого файла (для JSON):**
    Экспортированный JSON-файл будет содержать массив объектов, где каждый объект представляет одну размеченную задачу (новость). Примерная структура для одной задачи может выглядеть так:

    ```json
    [
      {
         "id": 132, // Уникальный идентификатор задачи в Label Studio
         "annotations": [ // Массив аннотаций для этой задачи (обычно одна, если нет review)
            {
            "id": 32, // ID аннотации
            "completed_by": 1, // ID пользователя, выполнившего разметку
            "result": [ // Массив фактических разметок (сущностей)
               {
                  "value": {
                  "start": 15,     // Начальный индекс символа сущности в тексте
                  "end": 21,       // Конечный индекс символа сущности (не включая)
                  "text": "SpaceX", // Текст выделенной сущности
                  "labels": [      // Список меток (обычно одна для NER)
                     "ORG"
                  ]
                  },
                  "id": "efpefyI5IN", // Уникальный ID этой конкретной метки
                  "from_name": "label", // Имя тега <Labels> из XML-конфигурации
                  "to_name": "text",   // Имя тега <Text> из XML-конфигурации
                  "type": "labels",
                  "origin": "manual" // Указывает, что разметка сделана вручную
               },
               // ... другие размеченные сущности для этой задачи ...
               {
                  "value": {
                  "start": 40,
                  "end": 55,
                  "text": "ракету Falcon 9",
                  "labels": [
                     "PRODUCT"
                  ]
                  },
                  "id": "h74F5AQxzw",
                  "from_name": "label",
                  "to_name": "text",
                  "type": "labels",
                  "origin": "manual"
               }
            ],
            // ... другая метаинформация об аннотации (was_cancelled, created_at, lead_time и т.д.) ...
            "task": 132 // Ссылка на ID задачи
            }
         ],
         "file_upload": "41c406e4-news_data.txt", // Имя исходного файла (если применимо)
         "data": {
            // Поле, содержащее исходные данные для разметки.
            // Имя этого поля (здесь "text") соответствует тому, что было указано 
            // в XML-конфигурации в атрибуте value тега <Text> (например, $text).
            "text": "1. Заголовок: \"SpaceX успешно запустила ракету Falcon 9 с миссией Starlink-45.\" Текст: \"Компания SpaceX, основанная Илоном Маском, сегодня осуществила успешный запуск ракеты-носителя Falcon 9 с очередной партией интернет-спутников Starlink. Старт был произведен с космодрома Ванденберг в Калифорнии.\""
         },
         "meta": {}, // Дополнительные метаданные
         // ... другая метаинформация о задаче (created_at, updated_at, project и т.д.) ...
         "project": 14 // ID проекта
      }
      // ... другие задачи ...
   ]
   ```

### 5. Обучение модели

После экспорта аннотаций из Label Studio, следующим шагом является обучение модели машинного обучения для извлечения именованных сущностей. Рассмотрим этот процесс на примере использования библиотеки **spaCy**.

*   **Тип модели и фреймворк:**
    *   **spaCy** – это популярная open-source библиотека для продвинутой обработки естественного языка (NLP) на Python. Она предоставляет эффективные инструменты для обучения кастомных моделей, включая модели для извлечения именованных сущностей (NER). spaCy хорошо работает с аннотациями, указывающими начальные и конечные смещения символов сущностей, что соответствует формату экспорта Label Studio.

*   **Процесс подготовки данных и обучения модели с spaCy:**

    1.  **Загрузка и парсинг аннотаций Label Studio:**
        *   Первым делом необходимо загрузить JSON-файл, экспортированный из Label Studio, и извлечь из него тексты и соответствующие им аннотации (позиции и метки сущностей).
        *   **Действие:** Написать Python-скрипт для чтения JSON-файла.
        *   **Данные из JSON:** Для каждой задачи (текста) нам нужны:
            *   Сам текст: `task['data']['text']` (или другое имя поля, если оно было изменено в конфигурации Label Studio).
            *   Список сущностей: Из `task['annotations'][0]['result']`, где каждый элемент содержит `value['start']`, `value['end']`, `value['text']`, и `value['labels'][0]`.

            ```python
            import json

            def load_label_studio_data(json_filepath):
                with open(json_filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                return data
            
            # label_studio_output = load_label_studio_data("path/to/your/export.json")
            ```

    2.  **Преобразование данных в формат spaCy:**
        *   spaCy для обучения NER-моделей ожидает данные в специфическом формате: список кортежей, где каждый кортеж состоит из текста и словаря с ключом `"entities"`. Значением этого ключа является список кортежей, каждый из которых описывает одну сущность: `(start_char_offset, end_char_offset, LABEL_STRING)`.
        *   **Действие:** Написать функцию для преобразования загруженных данных.

            ```python
            def convert_to_spacy_format(label_studio_data):
                spacy_training_data = []
                for task in label_studio_data:
                    text_content = ""
                    # Пытаемся получить текст. Ключ может отличаться.
                    if 'text' in task['data']:
                        text_content = task['data']['text']
                    elif task['data']: # Если 'text' нет, берем первый строковый ключ
                        for key_data in task['data']:
                            if isinstance(task['data'][key_data], str):
                                text_content = task['data'][key_data]
                                break
                    if not text_content:
                        print(f"Предупреждение: Текст не найден для задачи ID {task.get('id')}")
                        continue

                    entities = []
                    if task.get('annotations'):
                        for annotation_bundle in task['annotations']: # Обычно один бандл аннотаций
                            for annotation_result in annotation_bundle.get('result', []):
                                if annotation_result.get('type') == 'labels' and 'value' in annotation_result:
                                    value = annotation_result['value']
                                    if 'start' in value and 'end' in value and 'labels' in value and value['labels']:
                                        start_offset = value['start']
                                        end_offset = value['end']
                                        label = value['labels'][0] 
                                        entities.append((start_offset, end_offset, label))
                    
                    # Добавляем данные, даже если нет сущностей (важно для обучения NER)
                    spacy_training_data.append((text_content, {"entities": entities}))
                return spacy_training_data

            # Пример использования:
            # raw_data_from_ls = load_label_studio_data("path/to/your/export.json")
            # TRAIN_DATA = convert_to_spacy_format(raw_data_from_ls)
            
            # Пример одной записи в TRAIN_DATA:
            # ("Компания SpaceX, основанная Илоном Маском...", 
            #  {"entities": [(15, 21, "ORG"), (49, 60, "PERSON"), ...]})
            ```

    3.  **Создание и настройка NER-модели в spaCy:**
        *   **Действие:** Инициализировать модель spaCy (пустую или предобученную) и настроить компонент NER.
            *   Можно начать с пустой языковой модели (например, `spacy.blank("ru")` для русского языка) и добавить к ней NER-компонент.
            *   Либо загрузить предобученную модель (например, `ru_core_news_sm`) и дообучить её NER-компонент. Дообучение обычно дает лучшие результаты, если доступно достаточно данных.

            ```python
            import spacy
            import random
            from spacy.training.example import Example
            from spacy.util import minibatch, compounding

            # Используем TRAIN_DATA из предыдущего шага
            # TRAIN_DATA = [...] 

            def train_spacy_ner_model(training_data, model_name=None, new_model_name="custom_ner_model", output_dir=None, n_iter=20):
                """Обучает кастомную NER модель с spaCy."""
                if model_name is not None:
                    nlp = spacy.load(model_name)  # Загрузка существующей модели
                    print(f"Загружена модель '{model_name}'")
                else:
                    nlp = spacy.blank("ru")  # Создание пустой модели для русского языка
                    print("Создана пустая модель 'ru'")

                # Добавление NER компонента в пайплайн, если его нет
                if "ner" not in nlp.pipe_names:
                    ner = nlp.add_pipe("ner", last=True)
                else:
                    ner = nlp.get_pipe("ner")

                # Добавление новых меток сущностей в модель
                for _, annotations in training_data:
                    for ent in annotations.get("entities"):
                        ner.add_label(ent[2]) # ent[2] это метка (PERSON, ORG и т.д.)
                
                # Отключение других компонентов пайплайна для обучения только NER
                pipe_exceptions = ["ner", "trf_wordpiecer", "trf_tok2vec"]
                unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]

                with nlp.disable_pipes(*unaffected_pipes):
                    optimizer = nlp.begin_training()
                    for iteration in range(n_iter):
                        random.shuffle(training_data)
                        losses = {}
                        batches = minibatch(training_data, size=compounding(4.0, 32.0, 1.001))
                        for batch in batches:
                            examples = []
                            for text, annotations in batch:
                                doc = nlp.make_doc(text)
                                examples.append(Example.from_dict(doc, annotations))
                            nlp.update(examples, drop=0.35, sgd=optimizer, losses=losses)
                        print(f"Итерация {iteration + 1}/{n_iter}, Потери: {losses}")
                
                # Сохранение обученной модели
                if output_dir is not None:
                    nlp.to_disk(output_dir)
                    print(f"Обученная модель сохранена в {output_dir}")
                return nlp

            # Пример запуска обучения:
            # nlp_model = train_spacy_ner_model(TRAIN_DATA, output_dir="my_ner_model_v1", n_iter=30)
            ```

*   **Ссылки на релевантные ресурсы:**
    *   Документация spaCy по обучению NER: [https://spacy.io/usage/training#ner](https://spacy.io/usage/training#ner)
    *   Пример обучения NER от Label Studio: [https://labelstud.io/blog/tutorial-build-nlu-model-with-label-studio-and-rasa/](https://labelstud.io/blog/tutorial-build-nlu-model-with-label-studio-and-rasa/)


### 6. Итеративный процесс (Active Learning / Предразметка)

После обучения первой версии NER-модели (как описано в этапе 5), её можно использовать для ускорения и улучшения процесса разметки последующих данных. Этот итеративный подход, часто называемый "активным обучением" (Active Learning) или просто использованием модели для предразметки, является важной частью эффективного MLOps-пайплайна.

*   **Использование обученной модели для предразметки в Label Studio:**
    Label Studio позволяет подключать обученные модели в качестве **ML-бэкендов (ML Backends)**. Такой бэкенд может автоматически предлагать аннотации для новых, неразмеченных данных.

    1.  **Создание ML-бэкенда:**
        *   Необходимо обернуть вашу обученную spaCy NER-модель (или любую другую) в простой веб-сервис (например, с использованием Flask или FastAPI), который будет принимать текст на вход и возвращать предсказанные сущности в формате, понятном Label Studio.
        *   Label Studio предоставляет [репозиторий с примерами ML-бэкендов](https://github.com/HumanSignal/label-studio-ml-backend), включая примеры для spaCy.
        *   **Примерная логика ML-бэкенда для spaCy NER:**
            ```python
            # Фрагмент кода для ML-бэкенда (упрощенно)
            from label_studio_ml.model import LabelStudioMLBase
            from label_studio_ml.utils import get_label_config
            import spacy

            class SpacyNerPredictor(LabelStudioMLBase):
                def __init__(self, **kwargs):
                    super(SpacyNerPredictor, self).__init__(**kwargs)
                    # Загрузка вашей обученной модели
                    self.nlp_model = spacy.load("/path/to/your/my_ner_model_v1") 
                    # Получение информации о метках из конфигурации проекта Label Studio
                    self.labels = get_label_config(self.project_path).get('label_from_name') 
                                                                    # label_from_name - имя тега <Labels>

                def predict(self, tasks, **kwargs):
                    predictions = []
                    for task in tasks:
                        text_to_predict = task['data'].get('text') # или другой ключ
                        if not text_to_predict: continue

                        doc = self.nlp_model(text_to_predict)
                        results = []
                        for ent in doc.ents:
                            if ent.label_ in self.labels: # Предсказываем только те метки, что есть в проекте
                                results.append({
                                    "from_name": "label", # Должно соответствовать <Labels name="label" ...>
                                    "to_name": "text",    # Должно соответствовать <Text name="text" ...>
                                    "type": "labels",
                                    "value": {
                                        "start": ent.start_char,
                                        "end": ent.end_char,
                                        "text": ent.text,
                                        "labels": [ent.label_]
                                    }
                                })
                        predictions.append({"result": results})
                    return predictions
            ```

    2.  **Запуск ML-бэкенда:**
        *   Этот сервис (ML-бэкенд) запускается как отдельный процесс, доступный по сети для Label Studio. Его можно запустить локально или развернуть в Docker-контейнере.
        *   `label-studio-ml start /path/to/your/ml_backend_script_directory`

    3.  **Подключение ML-бэкенда к проекту Label Studio:**
        *   В настройках проекта Label Studio (Settings -> Machine Learning) добавить URL вашего запущенного ML-бэкенда.
        *   Label Studio начнет автоматически отправлять задачи на этот бэкенд для получения предсказаний.

*   **Процесс разметки с предсказаниями:**
    1.  Когда разметчик открывает новую задачу, Label Studio сначала запросит предсказания у ML-бэкенда.
    2.  Предсказанные сущности будут автоматически отображены на тексте (например, подсвечены соответствующими цветами).
    3.  **Задача разметчика:**
        *   **Проверить** корректность предсказаний.
        *   **Исправить** ошибки (удалить неверные сущности, добавить пропущенные, изменить границы или метки).
        *   **Доразметить** то, что модель не смогла определить.
    4.  Этот процесс обычно значительно **быстрее**, чем разметка с нуля, особенно если модель уже имеет приемлемое качество.

*   **Цикл улучшения модели:**
    1.  Размеченные (и исправленные) данные с использованием предсказаний снова экспортируются.
    2.  Эти новые данные добавляются к исходному обучающему набору.
    3.  Модель переобучается на расширенном и более качественном наборе данных.
    4.  Обновленная модель развертывается в ML-бэкенде.
    5.  Цикл повторяется.

    Этот итеративный подход позволяет постоянно улучшать качество модели и сокращать затраты на ручную разметку.


## Use Case 2: Детекция объектов на изображениях с помощью CVAT

### 1. Сбор и подготовка данных
   - Описание типа данных (изображения)
   - Источники (примеры)
   - Начальная подготовка (если есть, например, изменение размера, аугментация на этапе подготовки датасета)
   <!-- Скриншот: Пример исходных изображений -->

### 2. Настройка проекта/задачи в CVAT
   - Создание нового проекта и задачи
     <!-- Скриншот: Окно создания задачи в CVAT -->
   - Определение меток (labels) для объектов (car, pedestrian, traffic_light)
     <!-- Скриншот: Интерфейс определения меток в CVAT -->
   - Импорт данных (загрузка изображений)
     <!-- Скриншот: Окно загрузки изображений в CVAT -->

### 3. Процесс разметки
   - Описание интерфейса разметки для детекции объектов (Bounding Boxes)
   - Ключевые действия разметчика (рисование BBox, выбор метки)
     <!-- Скриншот: Интерфейс разметки BBox в CVAT -->
   - Использование инструментов (зум, панорамирование, горячие клавиши)
   - Использование AI-помощников (если есть, например, автодетекция или интерактивная сегментация для помощи в BBox)
     <!-- Скриншот: (Опционально) Пример использования AI-инструмента в CVAT -->

### 4. Экспорт размеченных данных
   - Выбор формата экспорта (например, COCO JSON, Pascal VOC, YOLO)
     <!-- Скриншот: Окно экспорта аннотаций из CVAT -->
   - Описание структуры экспортируемого файла

### 5. Преобразование данных (если необходимо)
   - Описание необходимости конвертации (например, если модель ожидает специфичный формат YOLO, а экспорт был в COCO)
   - Пример скрипта/инструмента для конвертации
   <!-- Скриншот: (Опционально) Пример структуры данных после конвертации -->

### 6. Обучение модели
   - Тип модели: Детектор объектов (например, YOLOv5, Faster R-CNN на PyTorch/TensorFlow)
   - Концептуальное описание процесса обучения (подготовка датасета, конфигурация модели, обучение, оценка)
   - Пример псевдокода или ссылки на репозитории моделей

### 7. Итеративный процесс (Active Learning)
   - Краткое описание, как обученная модель детекции может быть использована для автоматической аннотации новых данных в CVAT.